# -*- coding: utf-8 -*-
"""Final_code.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1YxBt0bTIiNNlp_KYMWcSYtBaSOrgZ1st
"""

# Import required libraries
import pandas as pd
from sklearn.model_selection import train_test_split, RandomizedSearchCV
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC
from sklearn.linear_model import LogisticRegression
from sklearn.naive_bayes import MultinomialNB
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, ConfusionMatrixDisplay
from imblearn.over_sampling import SMOTE
import matplotlib.pyplot as plt
import seaborn as sns
from collections import Counter

# Step 1: Load the dataset
data = pd.read_csv("/home/noroot/Downloads/Phishing_Email.csv", encoding="latin1", on_bad_lines="skip")

# Step 2: Clean the dataset
data = data[data["Email Type"].isin(["Safe Email", "Phishing Email"])]
data["Email Type"] = data["Email Type"].map({"Safe Email": 0, "Phishing Email": 1})

# Step 3: Split the data
X = data["Email Text"].fillna("")  # Fill missing email text with empty strings
y = data["Email Type"]
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)

# Step 4: Feature extraction using TF-IDF
print("Converting text into numerical features using TF-IDF...")
tfidf_vectorizer = TfidfVectorizer(stop_words="english", max_features=2000)
X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)
X_test_tfidf = tfidf_vectorizer.transform(X_test)

# Step 5: Handle class imbalance with SMOTE
print("Applying SMOTE to balance the dataset...")
smote = SMOTE(random_state=42)
X_train_tfidf_balanced, y_train_tfidf_balanced = smote.fit_resample(X_train_tfidf, y_train)

# Step 6: Initialize models
models = {
    "Random Forest": RandomForestClassifier(random_state=42),
    "SVM": SVC(random_state=42, probability=True),
    "Logistic Regression": LogisticRegression(max_iter=1000, random_state=42),
    "Naive Bayes": MultinomialNB(),
}

# Step 7: Hyperparameter tuning with RandomizedSearchCV
param_grids = {
    "Random Forest": {"n_estimators": [50, 100], "max_depth": [10, None]},
    "SVM": {"C": [0.1, 1, 10], "kernel": ["linear", "rbf"]},
}

def tune_and_train(model, param_grid, X_train, y_train):
    if param_grid:
        random_search = RandomizedSearchCV(
            model,
            param_distributions=param_grid,
            n_iter=5,
            cv=3,
            scoring="accuracy",
            random_state=42,
            n_jobs=-1,
        )
        random_search.fit(X_train, y_train)
        return random_search.best_estimator_
    else:
        model.fit(X_train, y_train)
        return model

# Step 8: Train and evaluate models
results = []
for model_name, model in models.items():
    print(f"Training {model_name} with TF-IDF...")
    tuned_model = tune_and_train(
        model, param_grids.get(model_name), X_train_tfidf_balanced, y_train_tfidf_balanced
    )
    y_pred = tuned_model.predict(X_test_tfidf)
    accuracy = accuracy_score(y_test, y_pred)
    report = classification_report(y_test, y_pred, output_dict=True)
    results.append({
        "Model": model_name,
        "Accuracy": accuracy,
        "Precision": report["weighted avg"]["precision"],
        "Recall": report["weighted avg"]["recall"],
        "F1-Score": report["weighted avg"]["f1-score"],
    })

    # Generate confusion matrix
    cm = confusion_matrix(y_test, y_pred)
    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=["Safe Email", "Phishing Email"])
    disp.plot(cmap="Blues")
    plt.title(f"Confusion Matrix for {model_name}")
    plt.show()

# Step 9: Visualize results
results_df = pd.DataFrame(results)

# Bar chart for accuracy comparison
plt.figure(figsize=(10, 6))
sns.barplot(data=results_df, x="Model", y="Accuracy", palette="viridis")
plt.title("Model Accuracy Comparison with TF-IDF")
plt.ylabel("Accuracy")
plt.xlabel("Model")
plt.tight_layout()
plt.show()

# Step 10: Most Frequently Used Words in Phishing Emails
phishing_emails = data[data["Email Type"] == 1]["Email Text"]
word_counts = Counter(" ".join(phishing_emails).split())
most_common_words = word_counts.most_common(20)
common_words_df = pd.DataFrame(most_common_words, columns=["Word", "Frequency"])

# Bar chart for most frequently used words
plt.figure(figsize=(12, 6))
sns.barplot(data=common_words_df, x="Frequency", y="Word", palette="plasma")
plt.title("Most Frequently Used Words in Phishing Emails")
plt.xlabel("Frequency")
plt.ylabel("Word")
plt.tight_layout()
plt.show()

# Step 11: Savfe results to CSV
results_df.to_csv("model_comparison_results_tfidf.csv", index=False)
print("Results saved to 'model_comparison_results_tfidf.csv'.")